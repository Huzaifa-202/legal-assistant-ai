# âš–ï¸ AI Lawyer â€“ Legal Document Q&A Assistant

AI Lawyer is a legal chatbot built using Retrieval-Augmented Generation (RAG) and the DeepSeek R1 model. It allows users to upload legal PDF documents and interactively ask questions, receiving context-aware, accurate answers grounded in the uploaded text.

---

## ğŸš€ Features

- ğŸ“„ Upload any legal PDF document  
- ğŸ§  Semantic search using FAISS vector store  
- ğŸ” Retrieve relevant context using LangChain  
- ğŸ’¬ Ask legal questions in natural language  
- âœ… Accurate responses with reduced hallucination  
- ğŸ–¥ï¸ Interactive UI powered by Streamlit  
- âš™ï¸ Uses local embedding via Ollama and LLM via GROQ (DeepSeek R1)  

---


## ğŸ–¥ï¸ User Interface Preview

Hereâ€™s a glimpse of the AI Lawyer web interface built using Streamlit:

### ğŸ“„ Upload Section

<img width="956" height="268" alt="upload" src="https://github.com/user-attachments/assets/227ec523-f0db-4316-93be-a29e992058b5" />


### ğŸ’¬ Ask Legal Questions

<img width="882" height="175" alt="question" src="https://github.com/user-attachments/assets/ae3b0b8e-bb8f-4406-a407-6e627020314e" />


### ğŸ¤– AI Response

<img width="852" height="436" alt="answers" src="https://github.com/user-attachments/assets/226a4cf9-0366-4f01-b8ea-6e5d10dc662f" />


---


## ğŸ§± Project Architecture

User Uploads PDF  
â€ƒâ€ƒâ†“  
PDF â†’ Text â†’ Chunks  
â€ƒâ€ƒâ†“  
Chunks â†’ Embeddings â†’ FAISS Index  
â€ƒâ€ƒâ†“  
Query â†’ Similarity Search â†’ Retrieved Docs  
â€ƒâ€ƒâ†“  
Prompt + Docs â†’ DeepSeek LLM â†’ Final Answer  

---

## ğŸ› ï¸ Tech Stack

| Layer               | Tool/Library              |
|--------------------|---------------------------|
| LLM                | DeepSeek R1 (via Groq)     |
| Embeddings         | Ollama (DeepSeek R1 1.5b)  |
| Framework          | LangChain                 |
| Vector Store       | FAISS                     |
| PDF Parsing        | PDFPlumber + LangChain    |
| UI                 | Streamlit                 |
| Deployment         | Docker                    |

---

## ğŸ§ª How to Use

### Prerequisites

- Python 3.10+
- Docker (for containerized deployment)
- GROQ API Key
- Ollama installed with `nomic-embed-text` model pulled

### Setup (Local)

1. Clone the repo:  
   git clone https://github.com/your-username/legal-assistant-ai.git  
   cd legal-assistant-ai  

2. Create `.env` file and add your API key:  
   GROQ_API_KEY=your_api_key_here  

3. Install dependencies:  
   pip install -r requirements.txt  

4. Start the app:  
   streamlit run frontend.py  

---

## ğŸ³ Docker Instructions

### Build the Docker image  
docker build -t ai-lawyer-app .

### Run the container  
docker run -p 8501:8501  
-e GROQ_API_KEY=your_api_key_here  
-v ${PWD}/pdfs:/app/pdfs  
-v ${PWD}/vectorstore:/app/vectorstore  
ai-lawyer-app

### Or use docker-compose  
docker compose up

---

## ğŸ³ Docker Image

You can directly pull and run the prebuilt image from Docker Hub:

ğŸ‘‰ [View on Docker Hub](https://hub.docker.com/r/huzaifaasad/ai-lawyer-app)
https://claude.ai/oauth/authorize?code=true&client_id=9d1c250a-e61b-44d9-88ed-5944d1962f5e&response_type=code&scope=org%3Acreate_api_key+user%3Aprofile+user%3Ainference&code_challenge=9a0FoT3tjNqaMv1m6BPP_BE6cy84Gfr7N-O_KlaEd2A&code_challenge_method=S256&state=PoXei2ilcWsTMoC9_-RHyaGFDf6PKYcVMAGe4F3p0hs&redirect_uri=https%3A%2F%2Fconsole.anthropic.com%2Foauth%2Fcode%2Fcallback
### Pull the image:  
docker pull huzaifaasad/ai-lawyer-app:latest

### Run the container:  
docker run -p 8501:8501 -e GROQ_API_KEY=your_api_key_here huzaifaasad/ai-lawyer-app:latest

---

## ğŸ“‚ Project Structure

legal-assistant-ai/  
â”œâ”€â”€ frontend.py             â†’ Streamlit UI  
â”œâ”€â”€ vector_database.py      â†’ PDF loader, splitter, embeddings, FAISS setup  
â”œâ”€â”€ rag_pipeline.py         â†’ LLM setup, doc retrieval, prompt chaining  
â”œâ”€â”€ requirements.txt  
â”œâ”€â”€ dockerfile  
â”œâ”€â”€ docker-compose.yml  
â”œâ”€â”€ .env                    â†’ GROQ API Key (not committed)  
â”œâ”€â”€ .gitignore  
â”œâ”€â”€ .gitattributes  
â”œâ”€â”€ pdfs/                   â†’ Uploaded PDFs  
â””â”€â”€ vectorstore/            â†’ FAISS vector database  

---

## ğŸ“š What is RAG?

RAG (Retrieval-Augmented Generation) enhances LLMs by retrieving contextually relevant information from custom knowledge bases (like PDFs) before generating a response. This helps:  
- ğŸ“Œ Reduce hallucinations  
- ğŸ“Œ Improve factual accuracy  
- ğŸ“Œ Enable private/custom document Q&A  

---

## ğŸ” Security Note

Make sure your `.env` file containing the API key is excluded from version control. The `.gitignore` already handles this.

---

## ğŸ“ Credits

- DeepSeek R1 â€“ Groq-hosted reasoning LLM  
- Ollama â€“ Local model serving for embeddings  
- LangChain â€“ Framework for chaining retrieval & generation  
- Streamlit â€“ UI for real-time legal chat  
- FAISS â€“ Fast vector search for document similarity  

---

## ğŸ“„ License

This project is open source and available under the MIT License.
